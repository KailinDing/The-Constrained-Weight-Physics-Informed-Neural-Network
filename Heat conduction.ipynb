{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from tqdm  import tqdm \n",
    "from tqdm import trange\n",
    "from pyDOE import lhs\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import warnings\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置中文字体\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 设置显示负号\n",
    "\n",
    "np.random.seed(2023)\n",
    "# 检查是否有可用的GPU设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def extract_mesh_from_inp(file_path):\n",
    "    \"\"\"\n",
    "    从 Abaqus .inp 文件中提取节点和 CPE3 元素信息，转换节点索引为 0-based。\n",
    "    \n",
    "    参数：\n",
    "        file_path: .inp 文件路径。\n",
    "    \n",
    "    返回：\n",
    "        nodes: list of (node_id, x, y)，节点 ID (0-based) 和坐标（仅 x, y）。\n",
    "        elements: list of [node_id1, node_id2, node_id3]，单元的节点索引 (0-based)。\n",
    "        node_sets: dict，节点集。\n",
    "        element_type: str，单元类型（如 'CPE3'）。\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    elements = []\n",
    "    node_sets = {}\n",
    "    element_type = None\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        reading_nodes = False\n",
    "        reading_elements = False\n",
    "        reading_nsets = False\n",
    "        current_nset = None\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"*Node\"):\n",
    "                reading_nodes = True\n",
    "                reading_elements = False\n",
    "                reading_nsets = False\n",
    "                continue\n",
    "            elif line.startswith(\"*Element\"):\n",
    "                reading_nodes = False\n",
    "                reading_elements = True\n",
    "                reading_nsets = False\n",
    "                element_type_match = re.search(r\"type=(\\w+)\", line)\n",
    "                element_type = element_type_match.group(1) if element_type_match else None\n",
    "                continue\n",
    "            elif line.startswith(\"*Nset\"):\n",
    "                reading_nodes = False\n",
    "                reading_elements = False\n",
    "                reading_nsets = True\n",
    "                current_nset = line.split('=')[-1].strip()\n",
    "                node_sets[current_nset] = []\n",
    "                continue\n",
    "            elif line.startswith(\"*End\") or line.startswith(\"*Elset\"):\n",
    "                reading_nodes = False\n",
    "                reading_elements = False\n",
    "                reading_nsets = False\n",
    "                continue\n",
    "            if reading_nodes:\n",
    "                node_data = re.split(r',\\s*', line.strip())\n",
    "                if len(node_data) >= 3:  # CPE3 只需 x, y 坐标\n",
    "                    try:\n",
    "                        node_id = int(node_data[0]) - 1  # 转换为 0-based\n",
    "                        x, y = map(float, node_data[1:3])  # 只取 x, y\n",
    "                        nodes.append((node_id, x, y))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            if reading_elements:\n",
    "                element_data = re.split(r',\\s*', line.strip())\n",
    "                if len(element_data) >= 4:  # CPE3: 1 element_id + 3 node_ids\n",
    "                    try:\n",
    "                        element_nodes = [int(n) - 1 for n in element_data[1:4]]  # 转换为 0-based\n",
    "                        if element_type == \"DC2D3\" and len(element_nodes) == 3:\n",
    "                            elements.append(element_nodes)\n",
    "                        else:\n",
    "                            print(f\"警告: 单元 {element_data[0]} 被跳过，无效节点数或类型\")\n",
    "                    except ValueError:\n",
    "                        print(f\"警告: 行数据无效: {line}\")\n",
    "                        continue\n",
    "            if reading_nsets:\n",
    "                if \"generate\" in line.lower():\n",
    "                    node_ids = re.split(r',\\s*', line.strip())\n",
    "                    if len(node_ids) >= 3:\n",
    "                        try:\n",
    "                            start, end, step = map(int, node_ids[:3])\n",
    "                            node_sets[current_nset].extend([n - 1 for n in range(start, end + 1, step)])\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                else:\n",
    "                    node_ids = re.split(r',\\s*', line.strip())\n",
    "                    if all(nid.strip().isdigit() for nid in node_ids if nid.strip()):\n",
    "                        node_sets[current_nset].extend([int(nid) - 1 for nid in node_ids if nid.strip()])\n",
    "\n",
    "    # 检查节点索引有效性\n",
    "    max_node_id = max([n[0] for n in nodes]) if nodes else -1\n",
    "    for e, elem in enumerate(elements):\n",
    "        for nid in elem:\n",
    "            if nid < 0 or nid > max_node_id:\n",
    "                print(f\"错误: 单元 {e+1} 包含无效节点索引 {nid + 1} (0-based: {nid})\")\n",
    "                return [], [], {}, None\n",
    "\n",
    "    return nodes, elements, node_sets, element_type\n",
    "\n",
    "def plot_2d_mesh(nodes, elements):\n",
    "    \"\"\"\n",
    "    绘制 CPE3 网格的二维线框可视化，跳过无效三角形。\n",
    "    \n",
    "    参数：\n",
    "        nodes: 节点列表 [(node_id, x, y), ...]\n",
    "        elements: 元素列表 [[node_id1, node_id2, node_id3], ...]\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # 提取节点坐标\n",
    "    nodes_array = np.array([n[1:3] for n in nodes])  # (num_nodes, 2)\n",
    "    invalid_elements = 0\n",
    "\n",
    "    # 绘制三角形元素\n",
    "    for e, node_ids in enumerate(elements):\n",
    "        # 获取三角形三个节点的坐标\n",
    "        coords = nodes_array[node_ids]  # (3, 2)\n",
    "        if len(set(node_ids)) != 3:\n",
    "            print(f\"警告: 单元 {e} 存在重复节点: {node_ids}\")\n",
    "            invalid_elements += 1\n",
    "            continue\n",
    "\n",
    "        x = coords[:, 0]\n",
    "        y = coords[:, 1]\n",
    "\n",
    "        # 检查三角形面积\n",
    "        v1 = coords[1] - coords[0]\n",
    "        v2 = coords[2] - coords[0]\n",
    "        area = 0.5 * abs(np.cross(v1, v2))\n",
    "        if area < 1e-10:\n",
    "            print(f\"警告: 单元 {e} 面积接近零 {area}，跳过\")\n",
    "            invalid_elements += 1\n",
    "            continue\n",
    "\n",
    "        # 闭合三角形\n",
    "        x = list(x) + [x[0]]\n",
    "        y = list(y) + [y[0]]\n",
    "        ax.plot(x, y, 'b-', alpha=0.5)\n",
    "\n",
    "    print(f\"总计跳过无效单元数: {invalid_elements}\")\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    plt.title('2D Triangular Mesh (CPE3)')\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')  # 确保比例相等以正确显示几何形状\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单线段的R函数距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linseg(x, y, xc1,yc1,R1):\n",
    "    \"\"\"单线段的R函数距离，防止零值\"\"\"\n",
    "    # print(R1.shape)\n",
    "    # print(x.shape)\n",
    "    # print(xc1.shape)\n",
    "    phi_i = abs((R1**2-(x - xc1)**2 - (y - yc1)**2)) / 2*R1\n",
    "\n",
    "    return phi_i\n",
    "\n",
    "def phi(x, y, xc,yc,R, m=1.0):\n",
    "    \"\"\"多边形R函数距离，基于边集合\"\"\"\n",
    "    RR = torch.zeros_like(x)\n",
    "    for i in range(len(R)):\n",
    "        # 直接从segments中提取每条边的起点和终点\n",
    "        xc1 = xc[i]\n",
    "        yc1 = yc[i]\n",
    "        R1= R[i]\n",
    "\n",
    "        phi_i = linseg(x, y, xc1,yc1,R1)\n",
    " \n",
    "        RR += 1.0 / phi_i**m\n",
    "\n",
    "    return 1.0 / RR**(1.0 / m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义非同质边界条件 g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_g(x, y, xc,yc,R, bc_values):\n",
    "    \"\"\"超限插值构造 g(x, y)，基于边集合\"\"\"\n",
    "    mu = 1.0\n",
    "    eps = 1e-20\n",
    "    weights = []\n",
    "    for i in range(len(R)):\n",
    "        xc1 = xc[i]\n",
    "        yc1 = yc[i]\n",
    "        R1= R[i]\n",
    "\n",
    "        phi_i = linseg(x, y, xc1,yc1,R1)+eps\n",
    "  \n",
    "        weights.append(phi_i**(-mu))\n",
    "   \n",
    "    weights = torch.stack(weights)\n",
    "\n",
    "    g_values = torch.tensor(bc_values, dtype=torch.float32, device=x.device)\n",
    "\n",
    "    w = weights / torch.sum(weights, dim=0)\n",
    "\n",
    "    g = torch.sum(w * g_values.view(-1, 1, 1), dim=0)\n",
    "   \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制距离函数云图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_phi(xc,yc,R, m=1.0,n_grid=100):\n",
    "    x = torch.linspace(-3, 3, n_grid)\n",
    "    y = torch.linspace(-3, 3, n_grid)\n",
    "    X, Y = torch.meshgrid(x, y, indexing='ij')\n",
    "    X_flat, Y_flat = X.reshape(-1), Y.reshape(-1)\n",
    "    print(X.shape)\n",
    "    \n",
    "    phi_vals = phi(X, Y, xc,yc,R, m=1.0).cpu().detach().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(X.cpu(), Y.cpu(), phi_vals, levels=20, cmap='viridis')\n",
    "    plt.colorbar(label='Distance Function φ(x, y)')\n",
    "    \n",
    "\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "def compute_shape_functions(nodes, elements):\n",
    "    \"\"\"\n",
    "    预计算每个单元高斯积分点的全局形函数及其导数，适应顺时针或逆时针\n",
    "    参数：\n",
    "        nodes: 节点坐标，形状为 (num_nodes, 2)\n",
    "        elements: 单元连接，形状为 (num_elements, 3)\n",
    "        device: PyTorch 设备\n",
    "    返回：\n",
    "        gauss_points: 积分点坐标，形状为 (num_elements, 2)\n",
    "        shape_vals: 形函数值，形状为 (num_elements, num_nodes)\n",
    "        shape_grads: 形函数导数，形状为 (num_elements, num_nodes, 2)\n",
    "        areas: 单元面积，形状为 (num_elements,)\n",
    "    \"\"\"\n",
    "    num_elements = elements.shape[0]\n",
    "    num_nodes = nodes.shape[0]\n",
    "    gauss_points = []\n",
    "    shape_vals = np.zeros((num_elements, num_nodes))\n",
    "    shape_grads = np.zeros((num_elements, num_nodes, 2))\n",
    "    areas = np.zeros(num_elements)\n",
    "    negative_grad_count = 0\n",
    "    total_grad_count = 0\n",
    "    for e, elem in enumerate(elements):\n",
    "        x1, y1 = nodes[elem[0]]\n",
    "        x2, y2 = nodes[elem[1]]\n",
    "        x3, y3 = nodes[elem[2]]\n",
    "        A_signed = 0.5 * ((x2 - x1)*(y3 - y1) - (x3 - x1)*(y2 - y1))\n",
    "        if A_signed < 0:  # 顺时针，翻转\n",
    "            elements[e] = [elem[0], elem[2], elem[1]]\n",
    "            x2, y2, x3, y3 = x3, y3, x2, y2\n",
    "            A_signed = -A_signed\n",
    "        A = abs(A_signed)\n",
    "        if A < 1e-10:\n",
    "            print(f\"Warning: Element {e} has near-zero area: {A}\")\n",
    "            A = 1e-10\n",
    "        areas[e] = A\n",
    "\n",
    "        x_g = (x1 + x2 + x3) / 3\n",
    "        y_g = (y1 + y2 + y3) / 3\n",
    "        gauss_points.append([x_g, y_g])\n",
    "\n",
    "        A1 = 0.5 * ((x2 - x_g)*(y3 - y_g) - (x3 - x_g)*(y2 - y_g))\n",
    "        A2 = 0.5 * ((x3 - x_g)*(y1 - y_g) - (x1 - x_g)*(y3 - y_g))\n",
    "        A3 = 0.5 * ((x1 - x_g)*(y2 - y_g) - (x2 - x_g)*(y1 - y_g))\n",
    "        N1 = A1 / A_signed\n",
    "        N2 = A2 / A_signed\n",
    "        N3 = A3 / A_signed\n",
    "\n",
    "        N_total = N1 + N2 + N3\n",
    "        expected = 0.3333333333333333\n",
    "        if abs(N_total - 1.0) > 1e-6 or min(N1, N2, N3) < -1e-6:\n",
    "            print(f\"Element {e}: Shape function sum={N_total}, N1={N1}, N2={N2}, N3={N3}, A_signed={A_signed}\")\n",
    "        elif abs(N1 - expected) > 1e-6 or abs(N2 - expected) > 1e-6 or abs(N3 - expected) > 1e-6:\n",
    "            print(f\"Element {e}: Unexpected shape functions, N1={N1}, N2={N2}, N3={N3}\")\n",
    "\n",
    "        shape_vals[e, elem[0]] = N1\n",
    "        shape_vals[e, elem[1]] = N2\n",
    "        shape_vals[e, elem[2]] = N3\n",
    "\n",
    "        b1, b2, b3 = y2 - y3, y3 - y1, y1 - y2\n",
    "        c1, c2, c3 = x3 - x2, x1 - x3, x2 - x1\n",
    "        dN_dx = np.array([b1/(2*A), b2/(2*A), b3/(2*A)])\n",
    "        dN_dy = np.array([c1/(2*A), c2/(2*A), c3/(2*A)])\n",
    "\n",
    "        for grad in dN_dx:\n",
    "            total_grad_count += 1\n",
    "            if grad < 0:\n",
    "                negative_grad_count += 1\n",
    "        for grad in dN_dy:\n",
    "            total_grad_count += 1\n",
    "            if grad < 0:\n",
    "                negative_grad_count += 1\n",
    "\n",
    "        dx_sum = dN_dx.sum()\n",
    "        dy_sum = dN_dy.sum()\n",
    "        if abs(dx_sum) > 1e-6 or abs(dy_sum) > 1e-6:\n",
    "            print(f\"Element {e}: dN_dx sum={dx_sum}, dN_dy sum={dy_sum}, dN_dx={dN_dx}, dN_dy={dN_dy}\")\n",
    "\n",
    "        shape_grads[e, elem[0], :] = [dN_dx[0], dN_dy[0]]\n",
    "        shape_grads[e, elem[1], :] = [dN_dx[1], dN_dy[1]]\n",
    "        shape_grads[e, elem[2], :] = [dN_dx[2], dN_dy[2]]\n",
    "\n",
    "\n",
    "    print(\"Area range:\", areas.min(), areas.max())\n",
    "    print(f\"Negative gradients: {negative_grad_count}/{total_grad_count} ({negative_grad_count/total_grad_count*100:.2f}%)\")\n",
    "    return (\n",
    "\n",
    "        torch.tensor(shape_vals, dtype=torch.float32, device=device),\n",
    "        torch.tensor(shape_grads, dtype=torch.float32, device=device)\n",
    "\n",
    "    )\n",
    "\n",
    "def generate_gp(nodes, elements, device='cpu'):\n",
    "    \"\"\"\n",
    "    生成三角形单元的高斯积分点（形心）和面积。\n",
    "\n",
    "    参数：\n",
    "        nodes (np.ndarray): 节点坐标，形状为 (n_nodes, 2)，每行是 [x, y]。\n",
    "        elements (np.ndarray): 三角形单元索引，形状为 (n_elements, 3)，每行包含三个节点索引。\n",
    "        device (str): 计算设备，默认为 'cpu'，可选 'cuda'。\n",
    "\n",
    "    返回：\n",
    "        Tuple[torch.Tensor, torch.Tensor]:\n",
    "            - areas: 每个三角形单元的面积，形状为 (n_elements,)。\n",
    "            - gauss_points: 每个三角形单元的形心坐标，形状为 (n_elements, 2)。\n",
    "    \"\"\"\n",
    "    # 转换为 NumPy 数组（确保输入格式一致）\n",
    "    nodes = np.asarray(nodes)\n",
    "    elements = np.asarray(elements)\n",
    "\n",
    "    # 获取三角形三个顶点的坐标\n",
    "    node1 = nodes[elements[:, 0]]  # 形状：(n_elements, 2)\n",
    "    node2 = nodes[elements[:, 1]]  # 形状：(n_elements, 2)\n",
    "    node3 = nodes[elements[:, 2]]  # 形状：(n_elements, 2)\n",
    "\n",
    "    # 计算面积（使用向量叉积公式）\n",
    "    x1, y1 = node1[:, 0], node1[:, 1]\n",
    "    x2, y2 = node2[:, 0], node2[:, 1]\n",
    "    x3, y3 = node3[:, 0], node3[:, 1]\n",
    "    areas = 0.5 * np.abs((x2 - x1) * (y3 - y1) - (x3 - x1) * (y2 - y1))\n",
    "\n",
    "    # 检查面积是否接近零\n",
    "    min_area = 1e-10\n",
    "    if np.any(areas < min_area):\n",
    "        print(f\"Warning: {np.sum(areas < min_area)} elements have area < {min_area}. Setting to {min_area}.\")\n",
    "        areas = np.maximum(areas, min_area)\n",
    "\n",
    "    # 计算形心（三个顶点坐标的平均值）\n",
    "    gauss_points = (node1 + node2 + node3) / 3.0\n",
    "\n",
    "    # 转换为 PyTorch 张量并移动到指定设备\n",
    "    areas = torch.tensor(areas, dtype=torch.float32, device=device)\n",
    "    gauss_points = torch.tensor(gauss_points, dtype=torch.float32, device=device)\n",
    "\n",
    "    return areas, gauss_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#########  PINN  ######### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均方误差 MSE\n",
    "mse_loss = torch.nn.MSELoss() \n",
    "\n",
    "# 定义 MAE 损失(绝对误差)\n",
    "mae_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.optim import lr_scheduler\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "class PINNs():\n",
    "    def __init__(\n",
    "        self, \n",
    "        activation, \n",
    "        device,\n",
    "        initial_lr, sadap,\n",
    "        k,\n",
    "        R,xc,yc,bc,\n",
    "        gp,  gp_shape, gp_shape_grad, areas,\n",
    "        mesh_nodes,\n",
    "        loss_threshold\n",
    "\n",
    "):\n",
    "\n",
    "        self.device = device\n",
    "        # self.t_point = t_point\n",
    "        ###  材料参数  ###\n",
    "\n",
    "\n",
    "        self.iter_res=0\n",
    "        self.iter_phi=0\n",
    "\n",
    "           \n",
    "        self.train_losses = []\n",
    "        self.train_losses_phi = []\n",
    "        self.end_time = []\n",
    "        self.R = R\n",
    "        self.bc = bc\n",
    "        self.xc = xc\n",
    "        self.yc = yc\n",
    "        self.k = torch.tensor(k, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "\n",
    "        self.gp = torch.tensor(gp, dtype=torch.float32, device=device)\n",
    "        self.gp_shape = torch.tensor(gp_shape, dtype=torch.float32, device=device)\n",
    "        self.gp_shape_grad_x = torch.tensor(gp_shape_grad[:, :, 0], dtype=torch.float32, device=device)\n",
    "        self.gp_shape_grad_y = torch.tensor(gp_shape_grad[:, :, 1], dtype=torch.float32, device=device)\n",
    "\n",
    "        self.areas = torch.tensor(areas, dtype=torch.float32, device=device)\n",
    "\n",
    "        beta_init = 0.0  # 初始值\n",
    "        ##u\n",
    "\n",
    "        self.gp_x = self.gp[:, 0].reshape(-1, 1)  # [N, 1]  \n",
    "        self.gp_y = self.gp[:, 1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "        self.mesh_nodes = torch.tensor(mesh_nodes, dtype=torch.float32, device=device)\n",
    "        self.mesh_nodes_x = self.mesh_nodes[:, 0].reshape(-1, 1)  # [N, 1]\n",
    "        self.mesh_nodes_y = self.mesh_nodes[:, 1].reshape(-1, 1)\n",
    "        \n",
    "\n",
    "        ####\n",
    "        self.beta_u = torch.full(self.mesh_nodes_x.shape, beta_init, requires_grad=True, device=device)  #\n",
    "\n",
    "        xx =  (torch.tensor(mesh_nodes).float().to(device))[:, 0].reshape(-1, 1) \n",
    "        yy =  (torch.tensor(mesh_nodes).float().to(device))[:, 1].reshape(-1, 1) \n",
    "        ##u\n",
    "\n",
    "\n",
    "\n",
    "        ##v\n",
    "\n",
    "        self.phi_val = phi(xx, yy, self.xc,self.yc,self.R, m=1.0)\n",
    "        self.g_val = boundary_g(xx, yy, self.xc, self.yc, self.R, self.bc)\n",
    "\n",
    "\n",
    "        ############################################\n",
    "\n",
    "\n",
    "        # 优化器：使用相同的设置\n",
    "        self.optimizer_res = torch.optim.LBFGS(\n",
    "            [self.beta_u], \n",
    "            lr=initial_lr, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-5, \n",
    "            tolerance_change = 1e-5 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"       # 使用强沃尔夫线搜索条件\n",
    "        )\n",
    "\n",
    "\n",
    "     \n",
    "        self.sadap_res=sadap #自适应学习率（是否）  每次更新时将学习率乘以 0.9（即每 1000 次迭代后，学习率减小到 90%）\n",
    "\n",
    "\n",
    "        self.optimizer_Adam_res = torch.optim.Adam(params=[self.beta_u], lr=initial_lr)\n",
    "\n",
    "\n",
    "        if self.sadap_res:\n",
    "            self.scheduler_res = lr_scheduler.StepLR(self.optimizer_Adam_res, step_size=1000, gamma=0.9)\n",
    "\n",
    "     # def optim_Adam(self,model):\n",
    "    #     opt_adam = torch.optim.Adam(params=model.parameters(), lr=self.initial_lr)\n",
    "    #     return opt_adam\n",
    "    def xavier_init(self,layer):\n",
    "        \"\"\"\n",
    "        对神经网络层进行 Xavier 初始化，包括权重和偏置\n",
    "        \n",
    "        Parameters:\n",
    "            - layer (torch.nn.Module): 神经网络层\n",
    "            \n",
    "        Notes:\n",
    "            该函数用于初始化线性层（nn.Linear），使用 Xavier 初始化方法，即将权重初始化为均匀分布，\n",
    "            将偏置初始化为零。\n",
    "        \"\"\"\n",
    "        if isinstance(layer, nn.Linear):  # 检查是否为线性层\n",
    "            nn.init.xavier_uniform_(layer.weight)  # 使用Xavier初始化方法初始化权重\n",
    "            nn.init.zeros_(layer.bias)  # 将偏置初始化为零\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #########################\n",
    "    #######         #########\n",
    "    #######  train  #########\n",
    "    #######         #########\n",
    "    #########################\n",
    "    def closure_res(self):\n",
    "\n",
    "        loss = self.lossf_res(\n",
    "            td=None,\n",
    "        )\n",
    "\n",
    "        # self.iter += 1\n",
    "        # if self.iter % 100 == 0:\n",
    "        #     print(f'Loss: {loss.item():.6f}')\n",
    "\n",
    "        self.optimizer_res.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def train_res(self, epochs):\n",
    " \n",
    "        #开启训练模式\n",
    "        # model = self.uv_dnn\n",
    "        # model.train()\n",
    "        self.lossf_res = self.loss_res_all\n",
    "        self.start_time = time.time()  # 记录迭代开始时间\n",
    "        \n",
    "        with trange(epochs, dynamic_ncols=True, ncols=1) as td:\n",
    "            for epoch in td:\n",
    "\n",
    "\n",
    "                loss = self.lossf_res(td=td, print_str=\"\", loss_model=mse_loss)\n",
    "\n",
    "\n",
    "                self.iter_res += 1\n",
    "\n",
    "                # 反向传播和优化\n",
    "                self.optimizer_Adam_res.zero_grad()\n",
    "#                 if torch.isnan(loss).any():\n",
    "#                     print(\"Loss contains NaN values. Check your model and input data.\")\n",
    "                loss.backward()\n",
    "                self.optimizer_Adam_res.step()\n",
    "\n",
    "                self.train_losses.append(loss)\n",
    "                self.end_time.append(time.time())  # 记录时间\n",
    "                if loss.item() < loss_threshold:\n",
    "                    print(f\"Stopping early at epoch {epoch} as loss {loss.item()} < {loss_threshold}\")\n",
    "                    break\n",
    "                \n",
    "                if self.sadap_res:\n",
    "                    self.scheduler_res.step()\n",
    "    \n",
    "        # self.optimizer_res.step(closure=self.closure_res)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    def predict_res(self):\n",
    "        # 模型 评估模式\n",
    "        \n",
    "        # 提取 u 和 v 分量\n",
    "        # output = self.MLS_PINN(uv)  # [num_elements, 2]\n",
    "        Ui = self.trial_function()#(1562,2)\n",
    "\n",
    "\n",
    "        # 计算一阶导数\n",
    "        u_x =  self.gp_shape_grad_x @ Ui*(-self.k)  # [N, 1]\n",
    "        u_y =  self.gp_shape_grad_y @ Ui*(-self.k)   # [N, 1]\n",
    "\n",
    "\n",
    "        u = self.gp_shape @ Ui\n",
    "\n",
    "\n",
    "        u = torch.tensor(u, dtype=torch.float32, requires_grad=True)\n",
    "        output = torch.cat([u,  u_x, u_y], dim=1)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def trial_function(self):\n",
    "        \"\"\"试探函数：u = g(x) + phi(x) * u_nn\"\"\"\n",
    "\n",
    "      \n",
    "        u = self.g_val + self.phi_val * self.beta_u\n",
    "\n",
    "        return u   \n",
    "\n",
    "\n",
    "\n",
    "    ####  能量函数   #### 线弹性\n",
    "    def compute_energy(self):\n",
    "        \"\"\"\n",
    "        计算总应变能\n",
    "        参数：\n",
    "            coords: 高斯积分点坐标，形状为 [num_elements, 2]\n",
    "        返回：\n",
    "            energy: 总能量（标量）\n",
    "        \"\"\"\n",
    "    \n",
    "        # 提取 u 和 v 分量\n",
    "        # output = self.MLS_PINN(uv)  # [num_elements, 2]\n",
    "\n",
    "        Ui = self.trial_function()#(1562,2)\n",
    "\n",
    "\n",
    "        # 计算一阶导数\n",
    "        u_x =  self.gp_shape_grad_x @ Ui # [N, 1]\n",
    "        u_y =  self.gp_shape_grad_y @ Ui  # [N, 1]\n",
    "\n",
    "\n",
    "        # 计算能量密度\n",
    "        energy_density = 0.5 * self.k*((u_x)**2+(u_y)**2)  # [num_elements, 1]\n",
    "\n",
    "        energy_density = energy_density.squeeze(-1)  # [num_elements]\n",
    "        \n",
    "\n",
    "        # 计算总能量\n",
    "        energy = torch.sum(energy_density * self.areas)\n",
    "\n",
    "        \n",
    "        return energy\n",
    "    \n",
    "       \n",
    "    def loss_RES(self, loss):\n",
    "     \n",
    "        energy = self.compute_energy()  # [num_elements, 1]\n",
    "        star = torch.zeros_like(energy).reshape(-1, 1)\n",
    "\n",
    "  \n",
    "        loss_res = loss(energy, star)\n",
    "        return loss_res       \n",
    "\n",
    "    \n",
    "\n",
    "#############################################    \n",
    "#    \n",
    "    def loss_res_all(self, td=None, print_str=\"\", loss_model=mse_loss):\n",
    "        loss_res = self.loss_RES(loss=loss_model)  \n",
    "        loss_all = loss_res\n",
    "        \n",
    "        if td is not None:\n",
    "            td.set_description(f\"RES: {loss_res.item():.6f}, ALL: {loss_res.item():.6f}\"+print_str)\n",
    "        \n",
    "        return loss_all    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功提取网格信息：\n",
      "节点数: 1072\n",
      "元素数: 1910\n",
      "节点集: ['Set-1, generate', 'Part-3-1']\n",
      "元素类型: None\n",
      "Area range: 0.0022573097611349475 0.009081047175102712\n",
      "Negative gradients: 5726/11460 (49.97%)\n"
     ]
    }
   ],
   "source": [
    "loss_threshold = 7081000000\n",
    "loss_threshold = 7080630000\n",
    "loss_threshold = 0\n",
    "# 指定 .inp 文件路径\n",
    "# file_path_ = r\"D:\\Jupyter\\CW_hidenn\\inp\\heat\\circle.inp\"  \n",
    "# txt_path = r\"D:\\Jupyter\\CW_hidenn\\txt\\heat\"\n",
    "# path_mesh = r\"D:\\Jupyter\\CW_hidenn\\fig\\heat\\mesh.jpg\"\n",
    "R = torch.tensor([\n",
    "    2.0,0.8,0.5,0.5\n",
    "])\n",
    "\n",
    "xc = torch.tensor([\n",
    "    0.0,0.8,-0.5,-0.5\n",
    "])\n",
    "yc = torch.tensor([\n",
    "    0.0,0.0,1,-1\n",
    "])\n",
    "nodes_, elements, node_sets, element_type = extract_mesh_from_inp(file_path_)\n",
    "print(f\"成功提取网格信息：\")\n",
    "print(f\"节点数: {len(nodes_)}\")\n",
    "print(f\"元素数: {len(elements)}\")\n",
    "print(f\"节点集: {list(node_sets.keys())}\")\n",
    "print(f\"元素类型: {element_type}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nodes = np.array([n[1:3] for n in nodes_])  # 提取 x, y, z\n",
    "elements = np.array(elements)  # 直接使用节点索引\n",
    "\n",
    "\n",
    "### 生成积分点,单元面积 ###\n",
    "areas,gp = generate_gp(nodes, elements)\n",
    "\n",
    "# plot_2d_mesh(nodes_, elements, gp, path_mesh, line_width=0.2, gp_color='red', gp_size=1)\n",
    "# MLS 形函数\n",
    "    ## gp_shape, gp_shape_grads\n",
    "gp_shape, gp_shape_grad = compute_shape_functions(nodes, elements)\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "activation='tanh'\n",
    "initial_lr=1\n",
    "sadap = True\n",
    "\n",
    "\n",
    "bc = [373.15,273.15,273.15,273.15]\n",
    "k=1\n",
    "model = PINNs(\n",
    "    activation, \n",
    "    device,\n",
    "    initial_lr, sadap,\n",
    "    k,\n",
    "    R,xc,yc,bc,\n",
    "    gp,  gp_shape, gp_shape_grad, areas,\n",
    "    nodes,\n",
    "    loss_threshold\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RES: 7080797696.000000, ALL: 7080797696.000000:   1%|          | 707/100000 [00:00<02:16, 728.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[323], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_res\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[315], line 152\u001b[0m, in \u001b[0;36mPINNs.train_res\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trange(epochs, dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m td:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m td:\n\u001b[1;32m--> 152\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlossf_res\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_res \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[315], line 256\u001b[0m, in \u001b[0;36mPINNs.loss_res_all\u001b[1;34m(self, td, print_str, loss_model)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_res_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, td\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, print_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_model\u001b[38;5;241m=\u001b[39mmse_loss):\n\u001b[1;32m--> 256\u001b[0m     loss_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_RES\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_model\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m    257\u001b[0m     loss_all \u001b[38;5;241m=\u001b[39m loss_res\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m td \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[315], line 244\u001b[0m, in \u001b[0;36mPINNs.loss_RES\u001b[1;34m(self, loss)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_RES\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss):\n\u001b[1;32m--> 244\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [num_elements, 1]\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     star \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(energy)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    248\u001b[0m     loss_res \u001b[38;5;241m=\u001b[39m loss(energy, star)\n",
      "Cell \u001b[1;32mIn[315], line 225\u001b[0m, in \u001b[0;36mPINNs.compute_energy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m Ui \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrial_function()\u001b[38;5;66;03m#(1562,2)\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# 计算一阶导数\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m u_x \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgp_shape_grad_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mUi\u001b[49m \u001b[38;5;66;03m# [N, 1]\u001b[39;00m\n\u001b[0;32m    226\u001b[0m u_y \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp_shape_grad_y \u001b[38;5;241m@\u001b[39m Ui  \u001b[38;5;66;03m# [N, 1]\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# 计算能量密度\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_res(epochs=100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
